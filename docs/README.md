# ğŸ¤– AI Summarization Platform

> **Professional text summarization with dual AI provider support**

A modern, enterprise-grade web application that provides intelligent text summarization using both cloud-based and local AI models. Compare results from multiple AI providers through a sleek, responsive interface.

![Platform Features](https://img.shields.io/badge/AI-Dual%20Provider-blue) ![Models](https://img.shields.io/badge/Models-16%20Available-green) ![Interface](https://img.shields.io/badge/UI-Modern%20Glass%20Morphism-purple) ![Setup](https://img.shields.io/badge/Setup-Automated-orange)

## âœ¨ **Key Features**

### ğŸ”„ **Dual Provider System**
- **â˜ï¸ Groq (Cloud)**: Ultra-fast inference with Llama, Mixtral, and Gemma models
- **ğŸ–¥ï¸ Ollama (Local)**: Privacy-focused, offline models running on your machine
- **ğŸ”„ Seamless Switching**: Compare results from cloud and local models side-by-side

### ğŸ¨ **Modern Interface**
- **Glass Morphism Design**: Professional, translucent UI with backdrop blur effects
- **Single-Page Layout**: No scrolling needed - everything visible at once
- **Responsive Design**: Perfect experience on desktop, tablet, and mobile
- **Real-time Status**: Live indicators for API connections and model availability

### ğŸ”’ **Smart Security**
- **Masked API Keys**: Environment variables automatically loaded and masked (gsk_****xyz)
- **User Override**: Click to override environment keys with custom ones
- **No Data Logging**: Your documents and API keys stay private

### ğŸ“„ **Document Processing**
- **PDF Upload**: Drag & drop PDF files for instant text extraction
- **Sample Documents**: Built-in sample documents for testing
- **Text Validation**: Smart content validation and error handling

## ğŸš€ **Quick Start**

### **1. Platform Setup**
```bash
git clone https://github.com/anandbalajibabu/llmPlayground.git
cd llmPlayground
./scripts/setup.sh
```

**ğŸ“ Important:** Configuration files are now organized in the `config/` directory:
- `config/requirements.txt` - Python dependencies  
- `config/env_example.txt` - Environment template

### **2. Choose Your AI Provider**

#### **Option A: Cloud Models (Groq) - Fast & Easy**
```bash
# 1. Get free API key from https://console.groq.com/keys
# 2. Create .env file from template
cp config/env_example.txt .env
# 3. Add your API key to .env file
echo "GROQ_API_KEY=your_actual_groq_key_here" >> .env
# OR edit .env manually with your preferred editor
```

#### **Option B: Local Models (Ollama) - Private & Free**
```bash
# Install Ollama and download models
./setup_ollama.sh
```

#### **Option C: Both Providers (Recommended)**
```bash
# 1. Setup local models
./setup_ollama.sh
# 2. Create .env file from template
cp config/env_example.txt .env
# 3. Add your Groq API key
echo "GROQ_API_KEY=your_actual_groq_key_here" >> .env
```

### **3. Start Application**
```bash
./scripts/start.sh
# Open http://localhost:8000
```

## ğŸ¯ **Available AI Models**

### â˜ï¸ **Groq (Cloud Models)**
| Model | Provider | Size | Speed | Use Case |
|-------|----------|------|-------|----------|
| **Llama 3.1 70B** | Meta | API | âš¡âš¡âš¡ | Best quality, complex tasks |
| **Llama 3.1 8B** | Meta | API | âš¡âš¡âš¡ | Balanced performance |
| **Mixtral 8x7B** | Mistral AI | API | âš¡âš¡ | Excellent reasoning |
| **Gemma 7B** | Google | API | âš¡âš¡âš¡ | Fast, efficient |

### ğŸ–¥ï¸ **Ollama (Local Models)**
| Model | Provider | Size | Privacy | Use Case |
|-------|----------|------|---------|----------|
| **Llama 3.1 8B** | Meta | 4.7GB | ğŸ”’ 100% | General purpose, private |
| **Mistral 7B** | Mistral AI | 4.1GB | ğŸ”’ 100% | Balanced local inference |
| **Phi-3 Mini** | Microsoft | 2.3GB | ğŸ”’ 100% | Lightweight, fast |
| **CodeLlama 7B** | Meta | 4.8GB | ğŸ”’ 100% | Code and technical content |

## ğŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Modern Web Interface                     â”‚
â”‚           (Glass Morphism â€¢ Responsive â€¢ Real-time)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Backend                           â”‚
â”‚              (Async â€¢ REST API â€¢ Validation)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Groq Provider   â”‚   â”‚  Ollama Provider â”‚
        â”‚   (Cloud API)     â”‚   â”‚  (Local Server)  â”‚
        â”‚                   â”‚   â”‚                  â”‚
        â”‚ â€¢ Llama 3.1       â”‚   â”‚ â€¢ Llama 3.1      â”‚
        â”‚ â€¢ Mixtral         â”‚   â”‚ â€¢ Mistral        â”‚
        â”‚ â€¢ Gemma           â”‚   â”‚ â€¢ Phi-3          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ **Project Structure**

```
ai-summarization-platform/
â”œâ”€â”€ ğŸš€ Core Application
â”‚   â”œâ”€â”€ modern_app.py              # FastAPI backend
â”‚   â”œâ”€â”€ llm_providers.py           # Dual provider system
â”‚   â”œâ”€â”€ document_processor.py      # PDF processing
â”‚   â””â”€â”€ templates/index.html       # Modern web interface
â”œâ”€â”€ âš™ï¸ Setup & Deployment
â”‚   â”œâ”€â”€ setup.sh                   # Platform setup
â”‚   â”œâ”€â”€ setup_ollama.sh           # Local models setup
â”‚   â”œâ”€â”€ run_app.py                # Application launcher
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                 # This file
â”‚   â”œâ”€â”€ SETUP_GUIDE.md           # Detailed setup guide
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md     # Architecture details
â””â”€â”€ ğŸ”§ Configuration
    â”œâ”€â”€ .env                      # Environment variables
    â””â”€â”€ env_example.txt          # Environment template
```

## ğŸ¨ **User Interface Features**

### **Step 1: Configure AI Providers**
- ğŸ”‘ **Groq API Key**: Auto-loaded from environment, masked for security
- ğŸ–¥ï¸ **Ollama Status**: Real-time connection monitoring
- ğŸ”„ **Model Selection**: Visual grid of available models with cloud/local indicators

### **Step 2: Upload Document**
- ğŸ“¤ **Drag & Drop**: Intuitive PDF upload with visual feedback
- ğŸ“‹ **Sample Documents**: Built-in test documents
- ğŸ‘ï¸ **Preview**: Instant document preview and metrics

### **Step 3: Generate & Compare**
- ğŸ¯ **Model Selection**: Choose multiple models for comparison
- ğŸ“ **Length Control**: Adjust summary length with slider
- ğŸ“Š **Results**: Side-by-side comparison with performance metrics

## ğŸ› ï¸ **System Requirements**

### **For Cloud Models (Groq)**
- âœ… Any computer with internet connection
- âœ… 2GB RAM minimum
- âœ… Modern web browser
- âœ… Groq API key (free tier available)

### **For Local Models (Ollama)**
- ğŸ’¾ **Minimum**: 8GB RAM, 20GB storage
- ğŸš€ **Recommended**: 16GB RAM, 50GB storage, SSD
- âš¡ **Optimal**: 32GB RAM, GPU with 8GB VRAM

## ğŸ”§ **Environment Variables**

```bash
# Cloud Provider (Optional)
GROQ_API_KEY=your_groq_api_key_here

# Local Provider (Optional)
OLLAMA_BASE_URL=http://localhost:11434

# Application Settings
APP_NAME=AI Summarization Platform
HOST=0.0.0.0
PORT=8000
DEBUG=False
```

## ğŸ“Š **Performance Comparison**

| Aspect | Groq (Cloud) | Ollama (Local) |
|--------|--------------|----------------|
| **Speed** | âš¡âš¡âš¡ Ultra-fast (2-5s) | âš¡ Moderate (10-30s) |
| **Privacy** | âš ï¸ API calls to cloud | âœ… 100% local/private |
| **Cost** | ğŸ’° Pay per use (free tier) | ğŸ†“ Free after setup |
| **Setup** | ğŸ¯ API key only | ğŸ”§ Local installation |
| **Internet** | ğŸ“¡ Required | âŒ Offline capable |
| **Models** | ğŸš€ Latest, curated | ğŸ  Full control |

## ğŸš€ **Deployment Options**

### **Local Development**
```bash
./start_app.sh
# Access: http://localhost:8000
```

### **Production Server**
```bash
# With environment variables
export GROQ_API_KEY="your_key"
export HOST="0.0.0.0"
export PORT="8000"
python modern_app.py
```

### **Docker Deployment**
```bash
# Build and run (Dockerfile not included, but easily adaptable)
docker build -t ai-summarization-platform .
docker run -p 8000:8000 -e GROQ_API_KEY="your_key" ai-summarization-platform
```

## ğŸ” **API Endpoints**

### **Web Interface**
- `GET /` - Main application interface

### **API Endpoints**
- `POST /api/configure-key` - Configure Groq API key
- `GET /api/models` - List available models
- `GET /api/groq-status` - Check Groq connection
- `GET /api/ollama-status` - Check Ollama status
- `POST /api/process-pdf` - Upload and process PDF
- `POST /api/summarize` - Generate summaries
- `GET /api/sample-documents` - Get sample documents

## ğŸ¤ **Contributing**

1. **Fork** the repository
2. **Create** feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** changes (`git commit -m 'Add amazing feature'`)
4. **Push** to branch (`git push origin feature/amazing-feature`)
5. **Open** Pull Request

## ğŸ“„ **License**

This project is open source and available under the [MIT License](LICENSE).

## ğŸ†˜ **Support & Documentation**

- ğŸ“– **Setup Guide**: [SETUP_GUIDE.md](SETUP_GUIDE.md)
- ğŸ—ï¸ **Architecture**: [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/anandbalajibabu/llmPlayground/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/anandbalajibabu/llmPlayground/discussions)

## ğŸ¯ **Roadmap**

- [ ] **More Providers**: Add support for OpenAI, Anthropic, Google AI
- [ ] **Document Types**: Support for Word, PowerPoint, text files
- [ ] **Batch Processing**: Multiple document processing
- [ ] **Export Options**: PDF, Word, JSON export
- [ ] **API Authentication**: User accounts and API keys
- [ ] **Performance Analytics**: Detailed model comparison metrics

---

<div align="center">

**ğŸš€ Built with FastAPI â€¢ âš¡ Powered by Groq & Ollama â€¢ ğŸ¨ Modern Design**

[â­ Star this repo](https://github.com/anandbalajibabu/llmPlayground) â€¢ [ğŸ› Report Issues](https://github.com/anandbalajibabu/llmPlayground/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/anandbalajibabu/llmPlayground/discussions)

</div>